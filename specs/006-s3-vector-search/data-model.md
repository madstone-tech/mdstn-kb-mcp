# Phase 1 Design: Data Model & Entities

**Status**: ✅ Complete  
**Date**: December 12, 2024  
**Feature**: Session 6 - S3 Vector Search & Semantic Capabilities

## Overview

This document defines the data model entities, fields, relationships, and validation rules for Session 6 vector search implementation. Entities are extracted from the feature specification and research findings.

---

## Entity Definitions

### 1. Vector Embedding

**Purpose**: Numerical representation of note content generated by Ollama, enabling semantic similarity search.

**Storage**: AWS S3 Vectors index (replicated across vector bucket and note metadata)

**Fields**:

| Field | Type | Required | Constraints | Validation |
|---|---|---|---|---|
| `id` | string (ULID) | Yes | Unique per vault | Must match note ULID |
| `model` | string | Yes | Fixed per indexing round | enum: `nomic-embed-text`, `mxbai-embed-large`, etc. |
| `dimensions` | int | Yes | Fixed per model | 384 (nomic-embed-text), 1024 (mxbai-embed-large) |
| `data` | []float32 | Yes | 384+ elements | Length must match model dimensions, should be normalized |
| `generated_at` | timestamp | Yes | Set on creation | Cannot be future-dated |
| `generated_by` | string | No | Tracking | Format: `kbvault/vX.X.X` |
| `confidence_score` | float32 | No | 0.0-1.0 | For future ML scoring |

**Example**:
```json
{
  "id": "01HQXYZ123456789ABCDEF",
  "model": "nomic-embed-text",
  "dimensions": 384,
  "data": [0.125, -0.084, 0.042, ...],
  "generated_at": "2024-12-12T10:30:00Z",
  "generated_by": "kbvault/v1.1.0",
  "confidence_score": 1.0
}
```

**Relationships**:
- 1:1 with Note (one embedding per note)
- Belongs to Vault (through Search Configuration)
- Generated by Ollama Model (reference via model field)

**Lifecycle**:
- Created: When note is saved (if semantic search enabled)
- Updated: When note content changes (if auto_regenerate enabled)
- Deleted: When note is deleted or vault is re-indexed with new model

**Validation Rules**:
- `dimensions` must match selected Ollama model
- `data` array length must equal `dimensions`
- `generated_at` must be recent (within last 24 hours by default)
- Vectors should be L2-normalized (verified via math.sqrt(sum(x²)) ≈ 1.0)

---

### 2. Search Result

**Purpose**: Combined text and semantic search result with ranking and explanation.

**Storage**: In-memory (not persisted)

**Fields**:

| Field | Type | Required | Constraints | Validation |
|---|---|---|---|---|
| `note_id` | string (ULID) | Yes | Unique per search | Must exist in vault |
| `relevance_score` | float32 | Yes | 0.0-1.0 | Score from hybrid calculation |
| `text_match_score` | float32 | Yes | 0.0-1.0 | TF-IDF score from text search |
| `semantic_match_score` | float32 | Yes | 0.0-1.0 | Cosine similarity score |
| `ranking_position` | int | Yes | >0 | Position in results (1-based) |
| `explanation` | string | No | Human-readable | Format: "Text: 85%, Semantic: 72%, Overall: 78%" |
| `note_title` | string | No | For display | First 100 chars of title |
| `note_preview` | string | No | For display | First 200 chars of content |

**Example**:
```json
{
  "note_id": "01HQXYZ123456789ABCDEF",
  "relevance_score": 0.84,
  "text_match_score": 0.90,
  "semantic_match_score": 0.72,
  "ranking_position": 1,
  "explanation": "Text: 90%, Semantic: 72%, Overall: 84% (weighted 70% text, 30% vector)",
  "note_title": "Distributed Systems Fundamentals",
  "note_preview": "A comprehensive guide to distributed systems concepts including..."
}
```

**Relationships**:
- Many per Search Query
- Links to Note (for displaying results)
- Computed from Embedding + Note

**Lifecycle**:
- Created: During search operation
- In-memory: No persistence (ephemeral)
- Deleted: After search completes (garbage collected)

**Validation Rules**:
- `relevance_score` = `text_match_score * text_weight + semantic_match_score * vector_weight`
- All scores 0.0-1.0 inclusive
- `ranking_position` is unique within single search result set
- Results typically ordered by `relevance_score` descending

---

### 3. Search Configuration

**Purpose**: Per-profile settings controlling how semantic search behaves.

**Storage**: TOML configuration file (Profile section)

**Fields**:

| Field | Type | Required | Default | Constraints | Validation |
|---|---|---|---|---|---|
| `semantic_enabled` | bool | Yes | true | Feature toggle | Must be explicitly set |
| `text_weight` | float32 | Yes | 0.7 | 0.0-1.0 | Sum with vector_weight ≤ 1.0 |
| `vector_weight` | float32 | Yes | 0.3 | 0.0-1.0 | = 1.0 - text_weight |
| `similarity_threshold` | float32 | Yes | 0.7 | 0.0-1.0 | Minimum score to include result |
| `ollama_model` | string | Yes | `nomic-embed-text` | Ollama model name | Must be installed locally |
| `ollama_endpoint` | string | Yes | `http://localhost:11434` | Valid URL | Must be reachable; support both http/https |
| `auto_regenerate` | string | Yes | `on_save` | enum | `on_save`, `manual`, `scheduled` |
| `batch_size` | int | No | 50 | 1-1000 | Batch size for embedding generation |
| `request_timeout` | duration | No | 30s | Duration | Per-request timeout for Ollama |
| `cache_enabled` | bool | No | true | Feature toggle | Enable in-memory embedding cache |
| `cache_max_size` | int | No | 10000 | >0 | Max embeddings to cache |
| `cache_ttl` | duration | No | 24h | Duration | Cache entry time-to-live |

**Example (TOML)**:
```toml
[profiles.research]
name = "Research Vault"
storage_backend = "s3"

[profiles.research.vector]
semantic_enabled = true
text_weight = 0.7
vector_weight = 0.3
similarity_threshold = 0.7
ollama_model = "nomic-embed-text"
ollama_endpoint = "http://localhost:11434"
auto_regenerate = "on_save"
batch_size = 50
request_timeout = "30s"
cache_enabled = true
cache_max_size = 10000
cache_ttl = "24h"
```

**Relationships**:
- Belongs to Profile (1:1)
- References Ollama Model (via `ollama_model`)
- Configures Embedding Generation (via `auto_regenerate`, `batch_size`)
- Configures Search Behavior (via `text_weight`, `vector_weight`, `similarity_threshold`)

**Lifecycle**:
- Created: When profile is created or first used
- Read: On every search operation (loaded via Viper)
- Updated: Via `kbvault config set` command
- Deleted: When profile is deleted

**Validation Rules**:
- `text_weight + vector_weight` should equal 1.0 (or will be normalized)
- `similarity_threshold` typically 0.5-0.9 (0.7 is industry standard)
- `ollama_endpoint` must be reachable (verified on first search)
- `batch_size` typically 10-100 (trade-off between latency and throughput)
- `request_timeout` should be ≥30s (Ollama first load can be slow)
- If `semantic_enabled` is false, other vector fields are ignored

---

### 4. Ollama Model

**Purpose**: Metadata about available Ollama embedding models for kbVault.

**Storage**: Not persisted; loaded from Ollama runtime or documentation

**Fields**:

| Field | Type | Example | Notes |
|---|---|---|---|
| `name` | string | `nomic-embed-text` | Model identifier |
| `dimensions` | int | 384 | Embedding vector size |
| `download_url` | string | `https://ollama.ai/library/nomic-embed-text` | Installation reference |
| `inference_speed` | string | `fast` | Relative speed: `fast`, `medium`, `slow` |
| `quality_tier` | string | `good` | `poor`, `fair`, `good`, `excellent` |
| `trained_on` | string | `Common crawl, code` | Training data summary |
| `parameters` | int | 137M | Model size (millions of parameters) |
| `memory_requirements` | string | `300MB` | Approx RAM needed |
| `is_free` | bool | true | No API costs |
| `recommendation` | string | `default` | `default`, `alternative`, `experimental` |

**Supported Models (Session 6)**:

| Name | Dimensions | Speed | Quality | Recommendation | Memory |
|---|---|---|---|---|---|
| `nomic-embed-text` | 384 | ⚡⚡⚡ Fast | ✓ Good | ✅ Default | 274MB |
| `mxbai-embed-large` | 1024 | ⚡⚡ Medium | ✓✓ Excellent | ✅ Alternative | 669MB |
| `jina-embeddings-v2-base-en` | 768 | ⚡⚡ Medium | ✓✓ Excellent | ✅ Alternative | 800MB |

**Example**:
```go
type OllamaModel struct {
	Name                 string
	Dimensions          int
	DownloadURL         string
	InferenceSpeed      string
	QualityTier         string
	TrainedOn           string
	Parameters          int
	MemoryRequirements  string
	IsFree              bool
	Recommendation      string
}

var DefaultModel = OllamaModel{
	Name:                "nomic-embed-text",
	Dimensions:         384,
	DownloadURL:        "https://ollama.ai/library/nomic-embed-text",
	InferenceSpeed:     "fast",
	QualityTier:        "good",
	TrainedOn:          "Common crawl, code",
	Parameters:         137,
	MemoryRequirements: "274MB",
	IsFree:             true,
	Recommendation:     "default",
}
```

**Relationships**:
- Referenced by Search Configuration (via `ollama_model`)
- Not persisted; metadata for user guidance

**Lifecycle**:
- Static throughout feature (curated list)
- Updated when new Ollama models released (future sessions)

---

## Storage Schema & Serialization

### Vector Embedding Storage (S3 Vectors)

**S3 Vector Bucket Structure**:
```
s3vectors://kbvault-vectors-{account-id}/
├── indexes/
│   └── default/                           # Default index per vault
│       ├── vectors/                       # Vector data store
│       │   ├── 01HQXYZ123.vec            # Binary vector file (optional)
│       │   └── 01HQXYZ124.vec
│       └── metadata/                      # Vector metadata
│           ├── 01HQXYZ123.json
│           └── 01HQXYZ124.json
```

**Vector Metadata (S3)** (JSON):
```json
{
  "note_id": "01HQXYZ123456789ABCDEF",
  "note_path": "notes/01HQXYZ.json",
  "title": "Distributed Systems Concepts",
  "tags": "systems,distributed,architecture",
  "created_at": "2024-12-11T10:00:00Z",
  "updated_at": "2024-12-12T10:30:00Z",
  "embedding_model": "nomic-embed-text",
  "embedding_dimensions": 384,
  "embedding_timestamp": "2024-12-12T10:30:00Z"
}
```

### Note Extension (Alongside Existing Note)

**Enhanced Note Structure**:
```json
{
  "id": "01HQXYZ123456789ABCDEF",
  "title": "Distributed Systems Concepts",
  "content": "...",
  "type": "note",
  "tags": ["systems", "distributed"],
  "links": [...],
  "vector": {
    "model": "nomic-embed-text",
    "dimensions": 384,
    "generated_at": "2024-12-12T10:30:00Z",
    "indexed": true
  }
}
```

Note: Full embedding vector (`data` array) is NOT stored in note file; only metadata. Actual vectors live in S3 Vectors for efficient similarity search.

### Search Configuration (TOML)

**File Location**: `~/.config/kbvault/config.toml`

**Format**:
```toml
[profiles.work]
name = "Work Vault"
storage_backend = "s3"
storage_path = "s3://mybucket/work-notes"

[profiles.work.vector]
semantic_enabled = true
text_weight = 0.7
vector_weight = 0.3
similarity_threshold = 0.7
ollama_model = "nomic-embed-text"
ollama_endpoint = "http://localhost:11434"
auto_regenerate = "on_save"
```

---

## State Transitions & Lifecycle

### Embedding Lifecycle

```
NOT_INDEXED → GENERATING → INDEXED → (AUTO_UPDATE or MANUAL_UPDATE) → INDEXED
                  ↓
              ERROR → RETRY or FALLBACK_TO_TEXT_ONLY

Triggers:
- NOT_INDEXED → GENERATING: Note created/modified, auto_regenerate enabled
- GENERATING → INDEXED: Ollama embedding succeeds
- GENERATING → ERROR: Ollama unavailable or timeout
- INDEXED → MANUAL_UPDATE: User runs `kbvault vectorize`
- INDEXED → (stays) INDEXED: User searches, uses cached embedding
```

### Search Configuration Lifecycle

```
INITIAL (defaults) → CONFIGURED (user sets values) → MODIFIED (user changes) → RECONFIGURED
                                                          ↓
                                                   REGENERATE_EMBEDDINGS
```

**Trigger for regeneration**:
- Model changed: `kbvault config set vector.ollama_model "mxbai-embed-large"`
- Endpoint changed: `kbvault config set vector.ollama_endpoint "http://remote:11434"`
- Text/vector weights changed: `kbvault config set vector.text_weight 0.5`

---

## Relationships & Constraints

### Entity Relationship Diagram

```
┌─────────────────────────────────┐
│          Note (Session 4)       │
│  - id, title, content, tags     │
└──────────────────┬──────────────┘
                   │
                   │ 1:1
                   │
        ┌──────────▼────────────┐
        │ Vector Embedding      │
        │ - id, data, model,    │
        │   dimensions,         │
        │   generated_at        │
        └──────────┬────────────┘
                   │
                   │ Query via S3 Vectors
                   │
        ┌──────────▼─────────────────┐
        │ Search Configuration        │
        │ (Per Profile via TOML)      │
        │ - semantic_enabled,         │
        │   text/vector_weight,       │
        │   ollama_model,             │
        │   similarity_threshold      │
        └──────────┬─────────────────┘
                   │
                   │ Configures
                   │
        ┌──────────▼──────────────┐
        │ Ollama Model            │
        │ (Static reference)      │
        │ - dimensions, speed,    │
        │   quality               │
        └─────────────────────────┘

┌──────────────────────────────────────┐
│      Search Query (In-Memory)        │
│  - query_text, query_embedding       │
└──────────────────┬───────────────────┘
                   │
        ┌──────────▼──────────────────┐
        │ Search Result (Multiple)    │
        │ - note_id, relevance_score, │
        │   text_match, semantic_match│
        └─────────────────────────────┘
```

### Uniqueness Constraints

| Entity | Field | Scope | Enforced |
|---|---|---|---|
| Vector Embedding | `id` | Per vault | S3 Vectors index (primary key) |
| Search Configuration | (implicit) | Per profile | TOML structure (1 per profile) |
| Note | `id` | Per vault | Existing Note storage |

### Validation Constraints

| Entity | Field | Rule | Severity |
|---|---|---|---|
| Vector Embedding | `dimensions` | Match Ollama model | ERROR (fail indexing) |
| Vector Embedding | `data.length` | = `dimensions` | ERROR (fail indexing) |
| Search Config | `text_weight + vector_weight` | ≤ 1.0 | WARNING (auto-normalize) |
| Search Config | `similarity_threshold` | 0.0-1.0 | ERROR (reject config) |
| Search Config | `ollama_endpoint` | Reachable HTTP(S) | WARNING (first search fails) |

---

## Data Evolution & Versioning

### Schema Versioning

**Current Version**: v1.0.0

**Compatibility**:
- Forward: Older kbVault ignores unknown fields (graceful degradation)
- Backward: New kbVault must handle missing vector fields (semantic search skipped)

**Future Evolution**:
- v1.1.0: Add cloud embedding provider support (OpenAI, HuggingFace) - deferred to future session
- v2.0.0: Change embedding storage format (would require migration)

### Migration Scenarios

**Scenario 1: Model Change** (text-embed-3-small → nomic-embed-text)
```
Action: User runs `kbvault config set vector.ollama_model "nomic-embed-text"`
Trigger: auto_regenerate = "on_save" → embeddings regenerated on next note save
Trigger: auto_regenerate = "manual" → user must run `kbvault vectorize` explicitly
```

**Scenario 2: Re-indexing** (bulk regeneration)
```
Command: `kbvault vectorize --batch-size 50 --force`
Action: Delete all embeddings, regenerate from Ollama
Time: ~10-15 minutes for 1000 notes
Cleanup: Clear embedding cache
```

**Scenario 3: Disable Semantic Search**
```
Action: User runs `kbvault config set vector.semantic_enabled false`
Effect: Text search only; embeddings remain (for re-enabling later)
```

---

## Implementation Notes

### Type Definitions (Go)

```go
package types

// VectorEmbedding represents a note embedding
type VectorEmbedding struct {
	ID            string    `json:"id"`
	Model         string    `json:"model"`
	Dimensions    int       `json:"dimensions"`
	Data          []float32 `json:"data"`
	GeneratedAt   time.Time `json:"generated_at"`
	GeneratedBy   string    `json:"generated_by,omitempty"`
	ConfidenceScore float32 `json:"confidence_score,omitempty"`
}

// SearchResult is a search result from text or semantic search
type SearchResult struct {
	NoteID              string    `json:"note_id"`
	RelevanceScore      float32   `json:"relevance_score"`
	TextMatchScore      float32   `json:"text_match_score"`
	SemanticMatchScore  float32   `json:"semantic_match_score"`
	RankingPosition     int       `json:"ranking_position"`
	Explanation         string    `json:"explanation,omitempty"`
	NoteTitle           string    `json:"note_title,omitempty"`
	NotePreview         string    `json:"note_preview,omitempty"`
}

// VectorSearchConfig per-profile configuration
type VectorSearchConfig struct {
	SemanticEnabled      bool          `toml:"semantic_enabled"`
	TextWeight           float32       `toml:"text_weight"`
	VectorWeight         float32       `toml:"vector_weight"`
	SimilarityThreshold  float32       `toml:"similarity_threshold"`
	OllamaModel          string        `toml:"ollama_model"`
	OllamaEndpoint       string        `toml:"ollama_endpoint"`
	AutoRegenerate       string        `toml:"auto_regenerate"` // on_save, manual, scheduled
	BatchSize            int           `toml:"batch_size,omitempty"`
	RequestTimeout       time.Duration `toml:"request_timeout,omitempty"`
	CacheEnabled         bool          `toml:"cache_enabled,omitempty"`
	CacheMaxSize         int           `toml:"cache_max_size,omitempty"`
	CacheTTL             time.Duration `toml:"cache_ttl,omitempty"`
}
```

### Database/Storage Considerations

- **Note metadata**: Enhanced with `vector` section (minimal impact on existing schema)
- **Vector embeddings**: Stored in S3 Vectors (separate from note file)
- **Search configuration**: In TOML (existing config system)
- **Cache**: In-memory only (not persisted; rebuilt on startup)

No database changes needed; leverages existing storage abstraction.

---

## Summary

| Entity | Persistence | Access Pattern | Lifecycle |
|---|---|---|---|
| **Vector Embedding** | S3 Vectors index | Query by similarity | Create on note save, delete on note delete |
| **Search Result** | In-memory | Ephemeral results | Create on search, discard after display |
| **Search Config** | TOML file | Read on every search | Create once, modified rarely |
| **Ollama Model** | Static reference | Read-only metadata | Fixed list, updated in future sessions |
| **Note** | S3 storage | Existing interface | Modified to include vector metadata |

All entities are properly scoped, validated, and integrated with existing kbVault architecture.
